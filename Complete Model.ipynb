{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.linear_model as LM\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "def buildNetwork(data):\n",
    "\tn=data[0].shape[1]\n",
    "\treg=l2(1e-4)\n",
    "\ty_train = np.asarray(data[1]).astype(int)\n",
    "\n",
    "\tif data[0].shape[1]>3:\n",
    "\t\tmodel = Sequential([\n",
    "\t\tInput(shape=(n,)),\n",
    "\t\tDense(n, activation=\"relu\"),\n",
    "\t\tDense(n//2, activation=\"relu\"),\n",
    "\t\tDense(1,activation=\"sigmoid\")\n",
    "\t\t])\n",
    "\t\tmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\t\ty_train = np.asarray(data[1])\n",
    "\t\tmodel.fit(\n",
    "\t    data[0],\n",
    "\t    y_train,\n",
    "\t    epochs=5)\n",
    "\telse:\n",
    "\t\tx_train, x_val, y_train, y_val = train_test_split(data[0], y_train, test_size = .20)\n",
    "\t\tmodel = Sequential([\n",
    "\t\tInput(shape=(n,)),\n",
    "\t\t# Dense(n, activation=\"relu\"),\n",
    "\t\tDense(n//2, activation=\"relu\"),\n",
    "\t\tDense(1,kernel_regularizer=reg,bias_regularizer=reg,activation=\"sigmoid\")\n",
    "\t\t])\n",
    "\t\tmodel.compile(loss='binary_crossentropy',optimizer = SGD(learning_rate=0.05,momentum=0.05))# optimizer=\"adam\")#, metrics=['accuracy'])\n",
    "\t\tmodel.fit(\n",
    "\t\tx_train,\n",
    "\t\ty_train,\n",
    "\t\tbatch_size=16,\n",
    "\t\tepochs=50,\n",
    "\t\tvalidation_data=(x_val,y_val),)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def processData(X,y):\n",
    "\t# X = preprocessing.scale(X)\n",
    "\tX,y = shuffle(X,y)\n",
    "\tx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = .20)\n",
    "\tscaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\tx_train=scaler.transform(x_train)\n",
    "\tx_test=scaler.transform(x_test)\n",
    "\treturn x_train,x_test, list(y_train), list(y_test)\n",
    "\n",
    "def buildLR(data):\n",
    "\tmodel = LM.LinearRegression()\n",
    "\tmodel.fit(data[0],data[1])\n",
    "\treturn model\n",
    "\n",
    "def buildSVM(data):\n",
    "\tmodel = svm.SVC()\n",
    "\tmodel.fit(data[0],data[1])\n",
    "\treturn model\n",
    "\n",
    "def buildRF(data):\n",
    "\tmodel = RandomForestClassifier()\n",
    "\tmodel.fit(data[0],data[1])\n",
    "\treturn model\n",
    "\n",
    "def buildGDA(data):\n",
    "\tmodel = LinearDiscriminantAnalysis()\n",
    "\tmodel.fit(data[0],data[1])\n",
    "\treturn model\n",
    "\n",
    "def buildKNN(data):\n",
    "\tmodel = KNeighborsClassifier(n_neighbors=85)\n",
    "\tmodel.fit(data[0],data[1])\n",
    "\treturn model\n",
    "\n",
    "def getAcc(model,x_test,y_test, str_rep, partial):\n",
    "\tpredictions = model.predict(x_test)\n",
    "\t# print(predictions)\n",
    "\t# print(predictions,y_test)\n",
    "\tpredictions = [1 if predictions[i]>=.5 else 0 for i in range(len(predictions))]\n",
    "\t# print(y_test,'\\n',predictions)\n",
    "\tm=len(y_test)\n",
    "\tacc = sum([1 if y_test[i]==predictions[i] else 0 for i in range(m)])/m\n",
    "\tif partial:\n",
    "\t\tstr_rep=\"partial \"+str_rep\n",
    "\tprint(\"the testing accuracy for {} is {}\".format(str_rep,acc))\n",
    "\treturn acc\n",
    "\n",
    "def plotclassifier(model,title,x_test,y_test,partial):\n",
    "    if partial:\n",
    "        plot_decision_regions(x_test,np.asarray(y_test).astype(int),clf=model,legend=2)\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "def runModels(X,y,lists,partial=False):\n",
    "\tx_train,x_test,y_train,y_test = processData(X,y)\n",
    "\ttrain = (x_train,y_train)\n",
    "\tlog_reg = buildLR(train)\n",
    "\tSVM = buildSVM(train)\n",
    "\tRF = buildRF(train)\n",
    "\tGDA = buildGDA(train)\n",
    "\tKNN = buildKNN(train)\n",
    "\tNN = buildNetwork(train)\n",
    "\tlists[0].append(getAcc(log_reg,x_test,y_test,\"Logistic Regression\", partial))\n",
    "\tlists[1].append(getAcc(SVM, x_test, y_test,\"Support Vector Machine\", partial))\n",
    "\tlists[2].append(getAcc(NN,x_test,y_test,\"Neural Network\",partial))\n",
    "\tlists[3].append(getAcc(KNN, x_test, y_test, \"K-Nearest Neighbors\", partial))\n",
    "\tlists[4].append(getAcc(GDA, x_test, y_test, \"Gaussian Discriminant Analysis\", partial))\n",
    "\tlists[5].append(getAcc(RF, x_test, y_test,\"Random Forest\", partial))\n",
    "\n",
    "\tif partial and len(lists[0])==1:\n",
    "\t\tplotclassifier(log_reg,\"Logistic Regression\",x_test,y_test,partial)\n",
    "\t\tplotclassifier(SVM,\"Support Vector Machine\",x_test,y_test,partial)\n",
    "\t\tplotclassifier(NN,\"Neural Networks\",x_test,y_test,partial)\n",
    "\t\tplotclassifier(KNN,\"K-Nearest Neighbors\",x_test,y_test,partial)\n",
    "\t\tplotclassifier(GDA,\"Gaussian Discriminant Analysis\",x_test,y_test,partial)\n",
    "\t\tplotclassifier(RF,\"Random Forest\",x_test,y_test,partial)\n",
    "\treturn lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7111\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8105 - val_loss: 0.7279\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7524 - val_loss: 0.7098\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7250 - val_loss: 0.7040\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7127 - val_loss: 0.7006\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7057 - val_loss: 0.6980\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7018 - val_loss: 0.6955\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6990 - val_loss: 0.6934\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6965 - val_loss: 0.6917\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6946 - val_loss: 0.6903\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6920 - val_loss: 0.6890\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6896 - val_loss: 0.6877\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6871 - val_loss: 0.6859\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6800 - val_loss: 0.6811\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6657 - val_loss: 0.6721\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6454 - val_loss: 0.6620\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6204 - val_loss: 0.6442\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5944 - val_loss: 0.6219\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5678 - val_loss: 0.5982\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5419 - val_loss: 0.5759\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5177 - val_loss: 0.5550\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4955 - val_loss: 0.5343\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4746 - val_loss: 0.5158\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4563 - val_loss: 0.4982\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4390 - val_loss: 0.4815\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4226 - val_loss: 0.4665\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4082 - val_loss: 0.4526\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3947 - val_loss: 0.4397\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3823 - val_loss: 0.4281\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3708 - val_loss: 0.4177\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3605 - val_loss: 0.4072\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3509 - val_loss: 0.3975\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3414 - val_loss: 0.3896\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3329 - val_loss: 0.3812\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3251 - val_loss: 0.3744\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3176 - val_loss: 0.3673\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3105 - val_loss: 0.3607\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3042 - val_loss: 0.3550\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2979 - val_loss: 0.3492\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2916 - val_loss: 0.3438\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2862 - val_loss: 0.3385\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2810 - val_loss: 0.3341\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2764 - val_loss: 0.3297\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2715 - val_loss: 0.3254\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2672 - val_loss: 0.3217\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2631 - val_loss: 0.3182\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2594 - val_loss: 0.3150\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2559 - val_loss: 0.3119\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2519 - val_loss: 0.3092\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2490 - val_loss: 0.3071\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2459 - val_loss: 0.3046\n",
      "the testing accuracy for partial Logistic Regression is 0.7941176470588235\n",
      "the testing accuracy for partial Support Vector Machine is 0.7647058823529411\n",
      "the testing accuracy for partial Neural Network is 0.7647058823529411\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.7647058823529411\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.7941176470588235\n",
      "the testing accuracy for partial Random Forest is 0.8235294117647058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.9704\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9852\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6930 - val_loss: 0.6946\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930 - val_loss: 0.6945\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6926 - val_loss: 0.6944\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923 - val_loss: 0.6942\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6925 - val_loss: 0.6940\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923 - val_loss: 0.6938\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6917 - val_loss: 0.6935\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6913 - val_loss: 0.6932\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6907 - val_loss: 0.6928\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6902 - val_loss: 0.6923\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6897 - val_loss: 0.6918\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6889 - val_loss: 0.6911\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6888 - val_loss: 0.6904\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6873 - val_loss: 0.6894\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6865 - val_loss: 0.6884\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6850 - val_loss: 0.6871\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6835 - val_loss: 0.6855\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6818 - val_loss: 0.6837\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6795 - val_loss: 0.6814\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6775 - val_loss: 0.6787\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6749 - val_loss: 0.6755\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6717 - val_loss: 0.6718\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6682 - val_loss: 0.6676\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6641 - val_loss: 0.6628\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6587 - val_loss: 0.6580\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6531 - val_loss: 0.6528\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6464 - val_loss: 0.6474\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6390 - val_loss: 0.6411\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6300 - val_loss: 0.6339\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6196 - val_loss: 0.6261\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6087 - val_loss: 0.6168\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5966 - val_loss: 0.6070\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5845 - val_loss: 0.5963\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5711 - val_loss: 0.5843\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5557 - val_loss: 0.5717\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5399 - val_loss: 0.5599\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5259 - val_loss: 0.5481\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5113 - val_loss: 0.5367\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4975 - val_loss: 0.5255\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4838 - val_loss: 0.5153\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4712 - val_loss: 0.5057\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4593 - val_loss: 0.4968\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4486 - val_loss: 0.4886\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4385 - val_loss: 0.4811\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4289 - val_loss: 0.4740\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4199 - val_loss: 0.4672\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4107 - val_loss: 0.4608\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4031 - val_loss: 0.4552\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3951 - val_loss: 0.4501\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3883 - val_loss: 0.4452\n",
      "the testing accuracy for partial Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for partial Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for partial Neural Network is 0.9705882352941176\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for partial Random Forest is 0.9411764705882353\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7538 - accuracy: 0.4370\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8519\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.9481\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9411764705882353\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5123 - val_loss: 0.4076\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5015 - val_loss: 0.3975\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4930 - val_loss: 0.3882\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4836 - val_loss: 0.3794\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4756 - val_loss: 0.3714\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4680 - val_loss: 0.3639\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4609 - val_loss: 0.3568\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4546 - val_loss: 0.3501\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4485 - val_loss: 0.3439\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4429 - val_loss: 0.3374\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4368 - val_loss: 0.3314\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4310 - val_loss: 0.3257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4256 - val_loss: 0.3203\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4209 - val_loss: 0.3151\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4161 - val_loss: 0.3100\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4124 - val_loss: 0.3063\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4069 - val_loss: 0.3014\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4028 - val_loss: 0.2967\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3986 - val_loss: 0.2922\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3947 - val_loss: 0.2884\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3909 - val_loss: 0.2847\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3875 - val_loss: 0.2813\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3843 - val_loss: 0.2779\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3811 - val_loss: 0.2746\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3782 - val_loss: 0.2713\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3755 - val_loss: 0.2682\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3732 - val_loss: 0.2650\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3701 - val_loss: 0.2622\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3673 - val_loss: 0.2594\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3647 - val_loss: 0.2563\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3616 - val_loss: 0.2533\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3593 - val_loss: 0.2508\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3563 - val_loss: 0.2485\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3533 - val_loss: 0.2462\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3516 - val_loss: 0.2438\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3486 - val_loss: 0.2413\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3451 - val_loss: 0.2392\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3419 - val_loss: 0.2371\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3398 - val_loss: 0.2356\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3376 - val_loss: 0.2341\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3357 - val_loss: 0.2321\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3336 - val_loss: 0.2301\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3315 - val_loss: 0.2288\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3295 - val_loss: 0.2275\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3277 - val_loss: 0.2262\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3263 - val_loss: 0.2249\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3249 - val_loss: 0.2235\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3233 - val_loss: 0.2220\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3222 - val_loss: 0.2206\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3208 - val_loss: 0.2191\n",
      "the testing accuracy for partial Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for partial Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for partial Neural Network is 0.9411764705882353\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for partial Random Forest is 0.9411764705882353\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5704\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.9407\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.8171 - val_loss: 0.6953\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7678 - val_loss: 0.6792\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7376 - val_loss: 0.6674\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7157 - val_loss: 0.6542\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6996 - val_loss: 0.6441\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6858 - val_loss: 0.6326\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6718 - val_loss: 0.6213\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6568 - val_loss: 0.6094\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6393 - val_loss: 0.5931\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6207 - val_loss: 0.5767\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6026 - val_loss: 0.5603\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5840 - val_loss: 0.5433\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5650 - val_loss: 0.5266\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5467 - val_loss: 0.5111\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5286 - val_loss: 0.4962\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5104 - val_loss: 0.4821\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4924 - val_loss: 0.4666\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4745 - val_loss: 0.4525\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4576 - val_loss: 0.4400\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4418 - val_loss: 0.4288\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4277 - val_loss: 0.4187\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4146 - val_loss: 0.4107\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4029 - val_loss: 0.4035\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3920 - val_loss: 0.3968\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3818 - val_loss: 0.3913\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3720 - val_loss: 0.3860\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3625 - val_loss: 0.3813\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3542 - val_loss: 0.3773\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3461 - val_loss: 0.3737\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3385 - val_loss: 0.3704\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3316 - val_loss: 0.3675\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3251 - val_loss: 0.3650\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3186 - val_loss: 0.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3127 - val_loss: 0.3607\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3070 - val_loss: 0.3591\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3019 - val_loss: 0.3577\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2968 - val_loss: 0.3566\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2918 - val_loss: 0.3558\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2877 - val_loss: 0.3550\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2833 - val_loss: 0.3543\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2791 - val_loss: 0.3539\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2754 - val_loss: 0.3536\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2716 - val_loss: 0.3534\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2680 - val_loss: 0.3534\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2650 - val_loss: 0.3536\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2621 - val_loss: 0.3539\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2589 - val_loss: 0.3542\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2561 - val_loss: 0.3546\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2535 - val_loss: 0.3551\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2511 - val_loss: 0.3555\n",
      "the testing accuracy for partial Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for partial Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for partial Neural Network is 0.9411764705882353\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for partial Random Forest is 0.9411764705882353\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7481\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.9630\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.7513 - val_loss: 0.7186\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6976 - val_loss: 0.6912\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6600 - val_loss: 0.6637\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6229 - val_loss: 0.6376\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5819 - val_loss: 0.5969\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5467 - val_loss: 0.5654\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5193 - val_loss: 0.5400\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4963 - val_loss: 0.5181\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4757 - val_loss: 0.5004\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4575 - val_loss: 0.4854\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4419 - val_loss: 0.4720\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4273 - val_loss: 0.4602\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4138 - val_loss: 0.4495\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4010 - val_loss: 0.4396\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3896 - val_loss: 0.4315\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3794 - val_loss: 0.4240\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3690 - val_loss: 0.4167\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3601 - val_loss: 0.4095\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3516 - val_loss: 0.4028\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3433 - val_loss: 0.3966\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3360 - val_loss: 0.3908\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3295 - val_loss: 0.3853\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3225 - val_loss: 0.3801\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3161 - val_loss: 0.3754\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3105 - val_loss: 0.3707\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3048 - val_loss: 0.3664\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2996 - val_loss: 0.3623\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2947 - val_loss: 0.3587\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2901 - val_loss: 0.3552\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2853 - val_loss: 0.3522\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2814 - val_loss: 0.3492\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2771 - val_loss: 0.3462\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2739 - val_loss: 0.3436\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2701 - val_loss: 0.3409\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2666 - val_loss: 0.3383\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2640 - val_loss: 0.3359\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2605 - val_loss: 0.3337\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2575 - val_loss: 0.3317\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2550 - val_loss: 0.3298\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2525 - val_loss: 0.3277\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2501 - val_loss: 0.3261\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2478 - val_loss: 0.3245\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2457 - val_loss: 0.3229\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2432 - val_loss: 0.3215\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2411 - val_loss: 0.3199\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2392 - val_loss: 0.3185\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2371 - val_loss: 0.3172\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2356 - val_loss: 0.3159\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2339 - val_loss: 0.3145\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2322 - val_loss: 0.3132\n",
      "the testing accuracy for partial Logistic Regression is 0.8823529411764706\n",
      "the testing accuracy for partial Support Vector Machine is 0.8823529411764706\n",
      "the testing accuracy for partial Neural Network is 0.8823529411764706\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8823529411764706\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8823529411764706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the testing accuracy for partial Random Forest is 0.8823529411764706\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9259\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9407\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9556\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9556\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5224 - val_loss: 0.5830\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5079 - val_loss: 0.5712\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4932 - val_loss: 0.5596\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4789 - val_loss: 0.5497\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4655 - val_loss: 0.5400\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4525 - val_loss: 0.5314\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4408 - val_loss: 0.5235\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4291 - val_loss: 0.5164\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4185 - val_loss: 0.5099\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4079 - val_loss: 0.5041\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3983 - val_loss: 0.4987\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3894 - val_loss: 0.4944\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3809 - val_loss: 0.4900\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3729 - val_loss: 0.4855\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3651 - val_loss: 0.4810\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3585 - val_loss: 0.4776\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3518 - val_loss: 0.4747\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3452 - val_loss: 0.4720\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3395 - val_loss: 0.4699\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3341 - val_loss: 0.4676\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3288 - val_loss: 0.4654\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3242 - val_loss: 0.4637\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3190 - val_loss: 0.4618\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3150 - val_loss: 0.4608\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3108 - val_loss: 0.4596\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3070 - val_loss: 0.4583\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3031 - val_loss: 0.4570\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2995 - val_loss: 0.4559\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2964 - val_loss: 0.4548\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2937 - val_loss: 0.4538\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2903 - val_loss: 0.4536\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2878 - val_loss: 0.4531\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2853 - val_loss: 0.4521\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2831 - val_loss: 0.4502\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2803 - val_loss: 0.4497\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2780 - val_loss: 0.4494\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2762 - val_loss: 0.4477\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2741 - val_loss: 0.4467\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2718 - val_loss: 0.4470\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2701 - val_loss: 0.4477\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2683 - val_loss: 0.4481\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2665 - val_loss: 0.4477\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2652 - val_loss: 0.4471\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2637 - val_loss: 0.4470\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2623 - val_loss: 0.4472\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2609 - val_loss: 0.4467\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2596 - val_loss: 0.4469\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2580 - val_loss: 0.4470\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2569 - val_loss: 0.4475\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2556 - val_loss: 0.4479\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.9117647058823529\n",
      "the testing accuracy for partial Neural Network is 0.9117647058823529\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9117647058823529\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.9117647058823529\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8666 - accuracy: 0.3037\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7111\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.9037\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.5770 - val_loss: 0.5672\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5539 - val_loss: 0.5450\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5327 - val_loss: 0.5243\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5134 - val_loss: 0.5051\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4964 - val_loss: 0.4872\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4805 - val_loss: 0.4705\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4659 - val_loss: 0.4551\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4532 - val_loss: 0.4406\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4409 - val_loss: 0.4270\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4297 - val_loss: 0.4141\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4194 - val_loss: 0.4019\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4101 - val_loss: 0.3904\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4013 - val_loss: 0.3794\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3929 - val_loss: 0.3692\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3851 - val_loss: 0.3595\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3782 - val_loss: 0.3504\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3714 - val_loss: 0.3417\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3653 - val_loss: 0.3334\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3595 - val_loss: 0.3257\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3543 - val_loss: 0.3183\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3488 - val_loss: 0.3113\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3441 - val_loss: 0.3045\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3394 - val_loss: 0.2981\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3354 - val_loss: 0.2919\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3313 - val_loss: 0.2860\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3277 - val_loss: 0.2804\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3239 - val_loss: 0.2751\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3204 - val_loss: 0.2700\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3173 - val_loss: 0.2654\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3148 - val_loss: 0.2608\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3116 - val_loss: 0.2565\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3089 - val_loss: 0.2523\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3068 - val_loss: 0.2482\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3042 - val_loss: 0.2446\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3019 - val_loss: 0.2409\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3001 - val_loss: 0.2374\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2978 - val_loss: 0.2342\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2958 - val_loss: 0.2310\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2941 - val_loss: 0.2279\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2925 - val_loss: 0.2249\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2909 - val_loss: 0.2220\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2896 - val_loss: 0.2194\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2881 - val_loss: 0.2168\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2866 - val_loss: 0.2143\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2853 - val_loss: 0.2118\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2841 - val_loss: 0.2096\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2828 - val_loss: 0.2073\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2817 - val_loss: 0.2053\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2807 - val_loss: 0.2033\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2798 - val_loss: 0.2013\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.9117647058823529\n",
      "the testing accuracy for partial Neural Network is 0.9117647058823529\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8823529411764706\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.9117647058823529\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6889\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.9630\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for Random Forest is 0.9411764705882353\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0638 - val_loss: 0.8887\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8615 - val_loss: 0.7790\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7656 - val_loss: 0.7344\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7282 - val_loss: 0.7166\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7154 - val_loss: 0.7081\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7084 - val_loss: 0.7020\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7025 - val_loss: 0.6985\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6981 - val_loss: 0.6955\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6940 - val_loss: 0.6936\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6918 - val_loss: 0.6922\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6882 - val_loss: 0.6896\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6850 - val_loss: 0.6861\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6828 - val_loss: 0.6826\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6784 - val_loss: 0.6801\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6758 - val_loss: 0.6737\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6693 - val_loss: 0.6678\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6630 - val_loss: 0.6611\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6532 - val_loss: 0.6517\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6432 - val_loss: 0.6386\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6277 - val_loss: 0.6138\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6090 - val_loss: 0.5848\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5872 - val_loss: 0.5540\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5628 - val_loss: 0.5249\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5393 - val_loss: 0.4989\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5155 - val_loss: 0.4777\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4950 - val_loss: 0.4593\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4782 - val_loss: 0.4439\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4639 - val_loss: 0.4303\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4519 - val_loss: 0.4177\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4418 - val_loss: 0.4076\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4338 - val_loss: 0.3984\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4253 - val_loss: 0.3897\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4182 - val_loss: 0.3817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4115 - val_loss: 0.3743\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4054 - val_loss: 0.3680\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4001 - val_loss: 0.3620\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3950 - val_loss: 0.3560\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3900 - val_loss: 0.3504\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3860 - val_loss: 0.3456\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3817 - val_loss: 0.3407\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3787 - val_loss: 0.3357\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3742 - val_loss: 0.3311\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3704 - val_loss: 0.3268\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3676 - val_loss: 0.3230\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3642 - val_loss: 0.3195\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3618 - val_loss: 0.3160\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3591 - val_loss: 0.3132\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3565 - val_loss: 0.3098\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3537 - val_loss: 0.3065\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3520 - val_loss: 0.3038\n",
      "the testing accuracy for partial Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for partial Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for partial Neural Network is 0.9411764705882353\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for partial Random Forest is 0.9117647058823529\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8815\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9630\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9630\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9704\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7116 - val_loss: 0.7070\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7050 - val_loss: 0.7014\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7000 - val_loss: 0.6966\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6959 - val_loss: 0.6929\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6929 - val_loss: 0.6896\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6896 - val_loss: 0.6862\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6868 - val_loss: 0.6826\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6836 - val_loss: 0.6793\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6812 - val_loss: 0.6761\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6779 - val_loss: 0.6719\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6744 - val_loss: 0.6672\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6709 - val_loss: 0.6620\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6678 - val_loss: 0.6560\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6634 - val_loss: 0.6497\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6592 - val_loss: 0.6424\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6546 - val_loss: 0.6347\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6499 - val_loss: 0.6258\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6441 - val_loss: 0.6160\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6379 - val_loss: 0.6052\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6316 - val_loss: 0.5936\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6246 - val_loss: 0.5819\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6179 - val_loss: 0.5698\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6103 - val_loss: 0.5563\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6027 - val_loss: 0.5425\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5932 - val_loss: 0.5281\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5847 - val_loss: 0.5152\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5752 - val_loss: 0.5016\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5653 - val_loss: 0.4880\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5554 - val_loss: 0.4742\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5447 - val_loss: 0.4612\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5345 - val_loss: 0.4487\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5231 - val_loss: 0.4360\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5124 - val_loss: 0.4233\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5012 - val_loss: 0.4110\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4907 - val_loss: 0.3998\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4803 - val_loss: 0.3895\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4699 - val_loss: 0.3794\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4598 - val_loss: 0.3697\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4509 - val_loss: 0.3614\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4430 - val_loss: 0.3531\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4350 - val_loss: 0.3452\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4282 - val_loss: 0.3387\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4214 - val_loss: 0.3320\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4149 - val_loss: 0.3255\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4092 - val_loss: 0.3195\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4030 - val_loss: 0.3137\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3980 - val_loss: 0.3082\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3925 - val_loss: 0.3032\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3878 - val_loss: 0.2991\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3836 - val_loss: 0.2949\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.9117647058823529\n",
      "the testing accuracy for partial Neural Network is 0.8823529411764706\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9117647058823529\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.9411764705882353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6519\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.9333\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6935 - val_loss: 0.6973\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6935 - val_loss: 0.6980\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6934 - val_loss: 0.6984\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6936 - val_loss: 0.6999\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930 - val_loss: 0.7001\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6932 - val_loss: 0.7000\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6932 - val_loss: 0.6998\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6931 - val_loss: 0.6996\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930 - val_loss: 0.7004\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6929 - val_loss: 0.7003\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930 - val_loss: 0.6999\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6931 - val_loss: 0.6998\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6939 - val_loss: 0.7009\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6929 - val_loss: 0.7010\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6927 - val_loss: 0.7011\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6927 - val_loss: 0.7017\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6926 - val_loss: 0.7014\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6933 - val_loss: 0.7013\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6927 - val_loss: 0.7013\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930 - val_loss: 0.7009\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6926 - val_loss: 0.7013\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6924 - val_loss: 0.7009\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6926 - val_loss: 0.7001\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6925 - val_loss: 0.6998\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6922 - val_loss: 0.6990\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6923 - val_loss: 0.6986\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6921 - val_loss: 0.6981\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923 - val_loss: 0.6978\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6917 - val_loss: 0.6971\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6914 - val_loss: 0.6958\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6914 - val_loss: 0.6953\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6907 - val_loss: 0.6941\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6905 - val_loss: 0.6930\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6900 - val_loss: 0.6915\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6898 - val_loss: 0.6892\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6891 - val_loss: 0.6865\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6882 - val_loss: 0.6841\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6881 - val_loss: 0.6810\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6864 - val_loss: 0.6781\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6854 - val_loss: 0.6755\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6842 - val_loss: 0.6719\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6829 - val_loss: 0.6685\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6816 - val_loss: 0.6646\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6797 - val_loss: 0.6611\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.6783 - val_loss: 0.6558\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6760 - val_loss: 0.6513\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6734 - val_loss: 0.6458\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6707 - val_loss: 0.6398\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6680 - val_loss: 0.6331\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6642 - val_loss: 0.6264\n",
      "the testing accuracy for partial Logistic Regression is 0.8529411764705882\n",
      "the testing accuracy for partial Support Vector Machine is 0.8529411764705882\n",
      "the testing accuracy for partial Neural Network is 0.7058823529411765\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8529411764705882\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8529411764705882\n",
      "the testing accuracy for partial Random Forest is 0.8235294117647058\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.5259\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7926\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.9259\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9630\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5156 - val_loss: 0.5934\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5025 - val_loss: 0.5820\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4901 - val_loss: 0.5715\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4781 - val_loss: 0.5608\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4672 - val_loss: 0.5505\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4559 - val_loss: 0.5407\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4455 - val_loss: 0.5321\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4361 - val_loss: 0.5236\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4274 - val_loss: 0.5157\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4185 - val_loss: 0.5087\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4108 - val_loss: 0.5019\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4032 - val_loss: 0.4949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3964 - val_loss: 0.4886\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3896 - val_loss: 0.4830\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3834 - val_loss: 0.4778\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3774 - val_loss: 0.4728\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3722 - val_loss: 0.4681\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3667 - val_loss: 0.4633\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3620 - val_loss: 0.4591\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3575 - val_loss: 0.4554\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3533 - val_loss: 0.4518\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3492 - val_loss: 0.4485\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3453 - val_loss: 0.4454\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3418 - val_loss: 0.4425\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3384 - val_loss: 0.4396\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3353 - val_loss: 0.4367\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3323 - val_loss: 0.4343\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3293 - val_loss: 0.4320\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3262 - val_loss: 0.4296\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3236 - val_loss: 0.4274\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3213 - val_loss: 0.4254\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3194 - val_loss: 0.4233\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3171 - val_loss: 0.4218\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3150 - val_loss: 0.4205\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3128 - val_loss: 0.4186\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3108 - val_loss: 0.4175\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3090 - val_loss: 0.4162\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3075 - val_loss: 0.4153\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3057 - val_loss: 0.4147\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3045 - val_loss: 0.4137\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3031 - val_loss: 0.4129\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3014 - val_loss: 0.4124\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3000 - val_loss: 0.4113\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2989 - val_loss: 0.4099\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2973 - val_loss: 0.4092\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2965 - val_loss: 0.4088\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2953 - val_loss: 0.4086\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2942 - val_loss: 0.4082\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2930 - val_loss: 0.4078\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2922 - val_loss: 0.4074\n",
      "the testing accuracy for partial Logistic Regression is 1.0\n",
      "the testing accuracy for partial Support Vector Machine is 1.0\n",
      "the testing accuracy for partial Neural Network is 1.0\n",
      "the testing accuracy for partial K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for partial Random Forest is 0.9411764705882353\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.5852\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.8370\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.9259\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9481\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9630\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5023 - val_loss: 0.6070\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4808 - val_loss: 0.6000\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4616 - val_loss: 0.5951\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4438 - val_loss: 0.5917\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4276 - val_loss: 0.5892\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4126 - val_loss: 0.5866\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3987 - val_loss: 0.5838\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3858 - val_loss: 0.5805\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3740 - val_loss: 0.5785\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3624 - val_loss: 0.5771\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3519 - val_loss: 0.5755\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3421 - val_loss: 0.5737\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3333 - val_loss: 0.5728\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3247 - val_loss: 0.5718\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3171 - val_loss: 0.5714\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3099 - val_loss: 0.5699\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3029 - val_loss: 0.5691\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2965 - val_loss: 0.5682\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2899 - val_loss: 0.5681\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2844 - val_loss: 0.5682\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2791 - val_loss: 0.5688\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2739 - val_loss: 0.5694\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2691 - val_loss: 0.5700\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2649 - val_loss: 0.5706\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2605 - val_loss: 0.5712\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2567 - val_loss: 0.5719\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2528 - val_loss: 0.5720\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2492 - val_loss: 0.5727\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2456 - val_loss: 0.5733\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2425 - val_loss: 0.5740\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2394 - val_loss: 0.5752\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2366 - val_loss: 0.5751\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2338 - val_loss: 0.5760\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2314 - val_loss: 0.5766\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2290 - val_loss: 0.5773\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2265 - val_loss: 0.5783\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2242 - val_loss: 0.5793\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2220 - val_loss: 0.5808\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2201 - val_loss: 0.5826\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2181 - val_loss: 0.5830\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2160 - val_loss: 0.5842\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2144 - val_loss: 0.5857\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2126 - val_loss: 0.5872\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2112 - val_loss: 0.5888\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2097 - val_loss: 0.5903\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2080 - val_loss: 0.5917\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2068 - val_loss: 0.5923\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2054 - val_loss: 0.5933\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2042 - val_loss: 0.5953\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2028 - val_loss: 0.5967\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.9117647058823529\n",
      "the testing accuracy for partial Neural Network is 0.9117647058823529\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9117647058823529\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.9117647058823529\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.6222\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.7863 - val_loss: 0.7780\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7488 - val_loss: 0.7411\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7221 - val_loss: 0.7124\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7011 - val_loss: 0.6885\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6831 - val_loss: 0.6670\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6667 - val_loss: 0.6467\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6504 - val_loss: 0.6269\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6351 - val_loss: 0.6071\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6188 - val_loss: 0.5869\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6027 - val_loss: 0.5669\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5861 - val_loss: 0.5462\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5692 - val_loss: 0.5253\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5521 - val_loss: 0.5047\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5352 - val_loss: 0.4854\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5198 - val_loss: 0.4667\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5040 - val_loss: 0.4484\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4894 - val_loss: 0.4313\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4758 - val_loss: 0.4150\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4623 - val_loss: 0.3997\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4500 - val_loss: 0.3853\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4385 - val_loss: 0.3720\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4281 - val_loss: 0.3595\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4177 - val_loss: 0.3477\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4082 - val_loss: 0.3366\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3996 - val_loss: 0.3266\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3915 - val_loss: 0.3173\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3840 - val_loss: 0.3090\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3769 - val_loss: 0.3013\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3705 - val_loss: 0.2935\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3644 - val_loss: 0.2865\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3585 - val_loss: 0.2802\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3528 - val_loss: 0.2737\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3479 - val_loss: 0.2675\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.250 - 0s 8ms/step - loss: 0.3428 - val_loss: 0.2614\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3382 - val_loss: 0.2558\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3339 - val_loss: 0.2505\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3302 - val_loss: 0.2456\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3257 - val_loss: 0.2409\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3223 - val_loss: 0.2364\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3186 - val_loss: 0.2322\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3151 - val_loss: 0.2281\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3122 - val_loss: 0.2246\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3092 - val_loss: 0.2213\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3063 - val_loss: 0.2182\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3038 - val_loss: 0.2150\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3014 - val_loss: 0.2116\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2990 - val_loss: 0.2086\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2970 - val_loss: 0.2058\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2953 - val_loss: 0.2031\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2929 - val_loss: 0.2008\n",
      "the testing accuracy for partial Logistic Regression is 0.8235294117647058\n",
      "the testing accuracy for partial Support Vector Machine is 0.8235294117647058\n",
      "the testing accuracy for partial Neural Network is 0.8235294117647058\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8235294117647058\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8235294117647058\n",
      "the testing accuracy for partial Random Forest is 0.8529411764705882\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.8074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9704\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5484 - val_loss: 0.6253\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5236 - val_loss: 0.6143\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5046 - val_loss: 0.6041\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4877 - val_loss: 0.5948\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4739 - val_loss: 0.5866\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4610 - val_loss: 0.5791\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4496 - val_loss: 0.5717\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4394 - val_loss: 0.5654\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4303 - val_loss: 0.5590\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4214 - val_loss: 0.5533\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4137 - val_loss: 0.5483\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4062 - val_loss: 0.5436\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3995 - val_loss: 0.5386\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3928 - val_loss: 0.5345\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3867 - val_loss: 0.5303\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3811 - val_loss: 0.5263\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3759 - val_loss: 0.5228\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3709 - val_loss: 0.5194\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3662 - val_loss: 0.5162\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3619 - val_loss: 0.5140\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3580 - val_loss: 0.5120\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3543 - val_loss: 0.5094\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3505 - val_loss: 0.5075\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3471 - val_loss: 0.5054\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3436 - val_loss: 0.5031\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3405 - val_loss: 0.5015\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3378 - val_loss: 0.5004\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3352 - val_loss: 0.4994\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3327 - val_loss: 0.4980\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3299 - val_loss: 0.4969\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3274 - val_loss: 0.4955\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3250 - val_loss: 0.4947\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3229 - val_loss: 0.4940\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3208 - val_loss: 0.4928\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3184 - val_loss: 0.4916\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3166 - val_loss: 0.4910\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3148 - val_loss: 0.4897\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3132 - val_loss: 0.4887\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3112 - val_loss: 0.4884\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3095 - val_loss: 0.4876\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3082 - val_loss: 0.4867\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3068 - val_loss: 0.4857\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3050 - val_loss: 0.4852\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3038 - val_loss: 0.4851\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3022 - val_loss: 0.4849\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3005 - val_loss: 0.4846\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2993 - val_loss: 0.4838\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2976 - val_loss: 0.4835\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2964 - val_loss: 0.4831\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2953 - val_loss: 0.4829\n",
      "the testing accuracy for partial Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for partial Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for partial Neural Network is 0.9705882352941176\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for partial Random Forest is 0.9705882352941176\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7852\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.9407\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9704\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9361 - val_loss: 0.8302\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8310 - val_loss: 0.7718\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7809 - val_loss: 0.7375\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7499 - val_loss: 0.7112\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7270 - val_loss: 0.6950\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7092 - val_loss: 0.6828\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6917 - val_loss: 0.6694\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6737 - val_loss: 0.6620\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6569 - val_loss: 0.6487\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6377 - val_loss: 0.6316\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6154 - val_loss: 0.6132\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5931 - val_loss: 0.5985\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5736 - val_loss: 0.5861\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5519 - val_loss: 0.5744\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5315 - val_loss: 0.5649\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5138 - val_loss: 0.5528\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4976 - val_loss: 0.5400\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4827 - val_loss: 0.5262\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4671 - val_loss: 0.5136\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4538 - val_loss: 0.5020\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4418 - val_loss: 0.4909\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4314 - val_loss: 0.4819\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4218 - val_loss: 0.4741\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4128 - val_loss: 0.4669\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4047 - val_loss: 0.4603\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3969 - val_loss: 0.4541\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3898 - val_loss: 0.4483\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3832 - val_loss: 0.4428\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3769 - val_loss: 0.4375\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3716 - val_loss: 0.4327\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3659 - val_loss: 0.4288\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3605 - val_loss: 0.4249\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3558 - val_loss: 0.4217\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3509 - val_loss: 0.4182\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3470 - val_loss: 0.4148\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3426 - val_loss: 0.4119\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3390 - val_loss: 0.4093\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3354 - val_loss: 0.4071\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3320 - val_loss: 0.4046\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3290 - val_loss: 0.4022\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3256 - val_loss: 0.3999\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3232 - val_loss: 0.3982\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3204 - val_loss: 0.3965\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3175 - val_loss: 0.3945\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3154 - val_loss: 0.3922\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3131 - val_loss: 0.3907\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3111 - val_loss: 0.3892\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3085 - val_loss: 0.3880\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3066 - val_loss: 0.3868\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3050 - val_loss: 0.3854\n",
      "the testing accuracy for partial Logistic Regression is 1.0\n",
      "the testing accuracy for partial Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for partial Neural Network is 1.0\n",
      "the testing accuracy for partial K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for partial Random Forest is 0.9705882352941176\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6519\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.9185\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9556\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9704\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 1.0682 - val_loss: 0.9291\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8995 - val_loss: 0.8261\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8071 - val_loss: 0.7700\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.7537 - val_loss: 0.7374\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7238 - val_loss: 0.7211\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7107 - val_loss: 0.7109\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7029 - val_loss: 0.7047\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6978 - val_loss: 0.7015\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6964 - val_loss: 0.7002\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6951 - val_loss: 0.6992\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6949 - val_loss: 0.6980\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6941 - val_loss: 0.6974\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6940 - val_loss: 0.6967\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6938 - val_loss: 0.6964\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6936 - val_loss: 0.6963\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6939 - val_loss: 0.6962\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6934 - val_loss: 0.6962\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6936 - val_loss: 0.6963\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6938 - val_loss: 0.6961\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6932 - val_loss: 0.6960\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - val_loss: 0.6960\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - val_loss: 0.6960\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6932 - val_loss: 0.6958\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6933 - val_loss: 0.6958\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - val_loss: 0.6957\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6934 - val_loss: 0.6958\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6941 - val_loss: 0.6960\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6934 - val_loss: 0.6960\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6934 - val_loss: 0.6961\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6933 - val_loss: 0.6961\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6935 - val_loss: 0.6961\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6936 - val_loss: 0.6961\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6932 - val_loss: 0.6961\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6934 - val_loss: 0.6961\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6940 - val_loss: 0.6962\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6938 - val_loss: 0.6961\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6938 - val_loss: 0.6962\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6933 - val_loss: 0.6961\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6935 - val_loss: 0.6958\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - val_loss: 0.6958\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6935 - val_loss: 0.6959\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6937 - val_loss: 0.6958\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6938 - val_loss: 0.6956\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6938 - val_loss: 0.6955\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6933 - val_loss: 0.6956\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6940 - val_loss: 0.6958\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6934 - val_loss: 0.6959\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6936 - val_loss: 0.6958\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6935 - val_loss: 0.6959\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6932 - val_loss: 0.6957\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.8823529411764706\n",
      "the testing accuracy for partial Neural Network is 0.47058823529411764\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8823529411764706\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.8823529411764706\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6444\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.9037\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for Neural Network is 0.9411764705882353\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for Random Forest is 0.9411764705882353\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.7049 - val_loss: 0.6775\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6658 - val_loss: 0.6380\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6351 - val_loss: 0.6053\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6069 - val_loss: 0.5774\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5828 - val_loss: 0.5537\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5616 - val_loss: 0.5328\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.5421 - val_loss: 0.5141\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5252 - val_loss: 0.4970\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5075 - val_loss: 0.4815\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4932 - val_loss: 0.4678\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4792 - val_loss: 0.4553\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4667 - val_loss: 0.4439\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4552 - val_loss: 0.4332\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4443 - val_loss: 0.4233\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4345 - val_loss: 0.4144\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4254 - val_loss: 0.4060\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4174 - val_loss: 0.3982\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4092 - val_loss: 0.3909\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4018 - val_loss: 0.3842\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3950 - val_loss: 0.3778\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3891 - val_loss: 0.3718\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3828 - val_loss: 0.3663\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3768 - val_loss: 0.3611\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3718 - val_loss: 0.3562\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3671 - val_loss: 0.3516\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3624 - val_loss: 0.3472\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3583 - val_loss: 0.3432\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3543 - val_loss: 0.3395\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3508 - val_loss: 0.3359\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3473 - val_loss: 0.3327\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3443 - val_loss: 0.3296\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3415 - val_loss: 0.3266\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3382 - val_loss: 0.3237\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3361 - val_loss: 0.3210\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3328 - val_loss: 0.3184\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3308 - val_loss: 0.3160\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3282 - val_loss: 0.3138\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3264 - val_loss: 0.3117\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3243 - val_loss: 0.3097\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3222 - val_loss: 0.3077\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3206 - val_loss: 0.3059\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3189 - val_loss: 0.3041\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3173 - val_loss: 0.3025\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3156 - val_loss: 0.3009\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3147 - val_loss: 0.2993\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3132 - val_loss: 0.2978\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3118 - val_loss: 0.2964\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3102 - val_loss: 0.2951\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3088 - val_loss: 0.2938\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3081 - val_loss: 0.2927\n",
      "the testing accuracy for partial Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for partial Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for partial Neural Network is 0.9411764705882353\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for partial Random Forest is 0.9705882352941176\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8721 - accuracy: 0.4593\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.9111\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9704\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0522 - val_loss: 0.8292\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8707 - val_loss: 0.7426\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7846 - val_loss: 0.7133\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7426 - val_loss: 0.7017\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7168 - val_loss: 0.6983\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7042 - val_loss: 0.6976\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6997 - val_loss: 0.6967\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6957 - val_loss: 0.6960\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923 - val_loss: 0.6949\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6888 - val_loss: 0.6924\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6848 - val_loss: 0.6900\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6810 - val_loss: 0.6842\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6748 - val_loss: 0.6722\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6683 - val_loss: 0.6603\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6596 - val_loss: 0.6464\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6460 - val_loss: 0.6290\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6285 - val_loss: 0.6076\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6082 - val_loss: 0.5823\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5845 - val_loss: 0.5627\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5605 - val_loss: 0.5447\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5371 - val_loss: 0.5295\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5142 - val_loss: 0.5180\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4932 - val_loss: 0.5079\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4720 - val_loss: 0.4995\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4521 - val_loss: 0.4929\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4342 - val_loss: 0.4874\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4182 - val_loss: 0.4831\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4038 - val_loss: 0.4795\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3906 - val_loss: 0.4752\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3790 - val_loss: 0.4706\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3680 - val_loss: 0.4669\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3579 - val_loss: 0.4641\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3492 - val_loss: 0.4617\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3410 - val_loss: 0.4595\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3332 - val_loss: 0.4579\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3264 - val_loss: 0.4565\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3202 - val_loss: 0.4550\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3145 - val_loss: 0.4539\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3089 - val_loss: 0.4524\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3031 - val_loss: 0.4515\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2976 - val_loss: 0.4506\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2927 - val_loss: 0.4499\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2884 - val_loss: 0.4497\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2840 - val_loss: 0.4490\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2798 - val_loss: 0.4485\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2757 - val_loss: 0.4482\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2722 - val_loss: 0.4481\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2684 - val_loss: 0.4480\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2656 - val_loss: 0.4481\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2622 - val_loss: 0.4483\n",
      "the testing accuracy for partial Logistic Regression is 0.8823529411764706\n",
      "the testing accuracy for partial Support Vector Machine is 0.8823529411764706\n",
      "the testing accuracy for partial Neural Network is 0.8529411764705882\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8529411764705882\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8823529411764706\n",
      "the testing accuracy for partial Random Forest is 0.9411764705882353\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.5778\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8741\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.9630\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9704\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6927 - val_loss: 0.6891\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6915 - val_loss: 0.6880\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6899 - val_loss: 0.6868\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6884 - val_loss: 0.6857\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6868 - val_loss: 0.6843\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6858 - val_loss: 0.6826\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6833 - val_loss: 0.6807\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6812 - val_loss: 0.6785\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6787 - val_loss: 0.6760\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6749 - val_loss: 0.6730\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6713 - val_loss: 0.6693\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6660 - val_loss: 0.6651\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6609 - val_loss: 0.6602\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6546 - val_loss: 0.6548\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6478 - val_loss: 0.6487\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6402 - val_loss: 0.6413\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6315 - val_loss: 0.6336\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6222 - val_loss: 0.6244\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6116 - val_loss: 0.6143\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6001 - val_loss: 0.6034\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5882 - val_loss: 0.5918\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5754 - val_loss: 0.5802\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5613 - val_loss: 0.5677\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5470 - val_loss: 0.5553\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5327 - val_loss: 0.5430\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5185 - val_loss: 0.5311\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5049 - val_loss: 0.5200\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4921 - val_loss: 0.5080\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4800 - val_loss: 0.4966\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4691 - val_loss: 0.4857\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4585 - val_loss: 0.4754\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4479 - val_loss: 0.4654\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4386 - val_loss: 0.4560\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4305 - val_loss: 0.4471\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4217 - val_loss: 0.4387\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4135 - val_loss: 0.4307\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4066 - val_loss: 0.4232\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3997 - val_loss: 0.4167\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3940 - val_loss: 0.4113\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3887 - val_loss: 0.4062\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3836 - val_loss: 0.4013\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3791 - val_loss: 0.3968\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3747 - val_loss: 0.3924\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3704 - val_loss: 0.3883\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3665 - val_loss: 0.3845\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3636 - val_loss: 0.3809\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3597 - val_loss: 0.3776\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3566 - val_loss: 0.3743\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3538 - val_loss: 0.3712\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3508 - val_loss: 0.3682\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.9117647058823529\n",
      "the testing accuracy for partial Neural Network is 0.8529411764705882\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9117647058823529\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.9117647058823529\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8889\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9704\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9778\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 1.0\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5094 - val_loss: 0.5432\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4953 - val_loss: 0.5318\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4809 - val_loss: 0.5209\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4674 - val_loss: 0.5110\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4552 - val_loss: 0.5013\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4433 - val_loss: 0.4922\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4316 - val_loss: 0.4839\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4211 - val_loss: 0.4760\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4114 - val_loss: 0.4687\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4020 - val_loss: 0.4619\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3936 - val_loss: 0.4557\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3857 - val_loss: 0.4499\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3785 - val_loss: 0.4446\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3714 - val_loss: 0.4396\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3650 - val_loss: 0.4351\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3589 - val_loss: 0.4309\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3532 - val_loss: 0.4270\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3477 - val_loss: 0.4235\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3428 - val_loss: 0.4204\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3377 - val_loss: 0.4174\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3335 - val_loss: 0.4149\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3295 - val_loss: 0.4124\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3254 - val_loss: 0.4101\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3220 - val_loss: 0.4079\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3187 - val_loss: 0.4056\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3149 - val_loss: 0.4034\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3117 - val_loss: 0.4016\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3094 - val_loss: 0.3998\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3064 - val_loss: 0.3980\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3037 - val_loss: 0.3964\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3012 - val_loss: 0.3949\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2991 - val_loss: 0.3935\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2971 - val_loss: 0.3921\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2947 - val_loss: 0.3908\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2928 - val_loss: 0.3896\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2906 - val_loss: 0.3882\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2884 - val_loss: 0.3868\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2865 - val_loss: 0.3856\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2847 - val_loss: 0.3844\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2825 - val_loss: 0.3834\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2808 - val_loss: 0.3823\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2797 - val_loss: 0.3814\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2774 - val_loss: 0.3806\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2756 - val_loss: 0.3801\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2743 - val_loss: 0.3795\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2728 - val_loss: 0.3790\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2714 - val_loss: 0.3785\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2702 - val_loss: 0.3780\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2687 - val_loss: 0.3777\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2675 - val_loss: 0.3773\n",
      "the testing accuracy for partial Logistic Regression is 0.8823529411764706\n",
      "the testing accuracy for partial Support Vector Machine is 0.8823529411764706\n",
      "the testing accuracy for partial Neural Network is 0.8823529411764706\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8823529411764706\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8823529411764706\n",
      "the testing accuracy for partial Random Forest is 0.8823529411764706\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6889\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.9259\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9556\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9704\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9778\n",
      "the testing accuracy for Logistic Regression is 1.0\n",
      "the testing accuracy for Support Vector Machine is 1.0\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 1.0\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 1.0\n",
      "the testing accuracy for Random Forest is 1.0\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.8998 - val_loss: 0.7815\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8210 - val_loss: 0.7516\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7748 - val_loss: 0.7335\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7491 - val_loss: 0.7218\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7304 - val_loss: 0.7128\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7165 - val_loss: 0.7066\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7068 - val_loss: 0.7022\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6999 - val_loss: 0.6983\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6942 - val_loss: 0.6944\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6874 - val_loss: 0.6909\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6813 - val_loss: 0.6876\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6753 - val_loss: 0.6848\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6690 - val_loss: 0.6818\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6626 - val_loss: 0.6779\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6560 - val_loss: 0.6719\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6500 - val_loss: 0.6661\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6412 - val_loss: 0.6578\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6308 - val_loss: 0.6461\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6190 - val_loss: 0.6343\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6062 - val_loss: 0.6188\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5907 - val_loss: 0.6036\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5738 - val_loss: 0.5874\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5554 - val_loss: 0.5708\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5358 - val_loss: 0.5548\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5166 - val_loss: 0.5398\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4980 - val_loss: 0.5257\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4800 - val_loss: 0.5111\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4634 - val_loss: 0.4964\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4479 - val_loss: 0.4832\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4337 - val_loss: 0.4711\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4202 - val_loss: 0.4599\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4080 - val_loss: 0.4496\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3965 - val_loss: 0.4402\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3861 - val_loss: 0.4317\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3764 - val_loss: 0.4248\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3670 - val_loss: 0.4183\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3582 - val_loss: 0.4124\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3505 - val_loss: 0.4072\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3432 - val_loss: 0.4024\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3365 - val_loss: 0.3982\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3302 - val_loss: 0.3944\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3247 - val_loss: 0.3909\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3194 - val_loss: 0.3876\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3140 - val_loss: 0.3848\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3091 - val_loss: 0.3821\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3050 - val_loss: 0.3796\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3008 - val_loss: 0.3773\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2969 - val_loss: 0.3750\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2931 - val_loss: 0.3731\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2895 - val_loss: 0.3710\n",
      "the testing accuracy for partial Logistic Regression is 0.8823529411764706\n",
      "the testing accuracy for partial Support Vector Machine is 0.8823529411764706\n",
      "the testing accuracy for partial Neural Network is 0.8823529411764706\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8823529411764706\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8823529411764706\n",
      "the testing accuracy for partial Random Forest is 0.8823529411764706\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.5333\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8963\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9411764705882353\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6209 - val_loss: 0.5817\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6029 - val_loss: 0.5569\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5838 - val_loss: 0.5334\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5663 - val_loss: 0.5108\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5496 - val_loss: 0.4892\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5341 - val_loss: 0.4684\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5188 - val_loss: 0.4495\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5047 - val_loss: 0.4311\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4911 - val_loss: 0.4141\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4788 - val_loss: 0.3989\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4670 - val_loss: 0.3843\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4561 - val_loss: 0.3699\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4457 - val_loss: 0.3563\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4356 - val_loss: 0.3438\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4261 - val_loss: 0.3320\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4170 - val_loss: 0.3213\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4091 - val_loss: 0.3112\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4013 - val_loss: 0.3013\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3937 - val_loss: 0.2922\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3870 - val_loss: 0.2836\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3802 - val_loss: 0.2755\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3743 - val_loss: 0.2677\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3682 - val_loss: 0.2606\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3628 - val_loss: 0.2536\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3576 - val_loss: 0.2472\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3525 - val_loss: 0.2410\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3478 - val_loss: 0.2355\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3433 - val_loss: 0.2301\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3393 - val_loss: 0.2249\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3354 - val_loss: 0.2203\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3315 - val_loss: 0.2157\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3280 - val_loss: 0.2112\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3251 - val_loss: 0.2069\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3215 - val_loss: 0.2028\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3186 - val_loss: 0.1990\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3157 - val_loss: 0.1959\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3131 - val_loss: 0.1922\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3109 - val_loss: 0.1894\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3090 - val_loss: 0.1862\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3057 - val_loss: 0.1830\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3033 - val_loss: 0.1801\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3012 - val_loss: 0.1776\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2993 - val_loss: 0.1747\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2973 - val_loss: 0.1720\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2959 - val_loss: 0.1694\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2943 - val_loss: 0.1668\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2923 - val_loss: 0.1643\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2904 - val_loss: 0.1623\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2896 - val_loss: 0.1607\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2877 - val_loss: 0.1588\n",
      "the testing accuracy for partial Logistic Regression is 0.8235294117647058\n",
      "the testing accuracy for partial Support Vector Machine is 0.8235294117647058\n",
      "the testing accuracy for partial Neural Network is 0.8235294117647058\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.8529411764705882\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.8235294117647058\n",
      "the testing accuracy for partial Random Forest is 0.8529411764705882\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8000\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.9111\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9556\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9926\n",
      "the testing accuracy for Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for Neural Network is 0.9411764705882353\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for Random Forest is 0.9411764705882353\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6859 - val_loss: 0.6783\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6739 - val_loss: 0.6666\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6617 - val_loss: 0.6550\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6507 - val_loss: 0.6431\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6377 - val_loss: 0.6304\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6243 - val_loss: 0.6169\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6108 - val_loss: 0.6029\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5968 - val_loss: 0.5877\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5819 - val_loss: 0.5720\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5671 - val_loss: 0.5562\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5520 - val_loss: 0.5405\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5376 - val_loss: 0.5252\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5244 - val_loss: 0.5101\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5106 - val_loss: 0.4953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4983 - val_loss: 0.4808\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4851 - val_loss: 0.4669\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4737 - val_loss: 0.4540\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4629 - val_loss: 0.4419\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4534 - val_loss: 0.4304\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4444 - val_loss: 0.4195\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4356 - val_loss: 0.4091\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4274 - val_loss: 0.3991\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4200 - val_loss: 0.3898\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4134 - val_loss: 0.3808\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4065 - val_loss: 0.3721\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4001 - val_loss: 0.3640\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3941 - val_loss: 0.3561\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3885 - val_loss: 0.3487\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3837 - val_loss: 0.3415\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3781 - val_loss: 0.3348\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3735 - val_loss: 0.3283\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3690 - val_loss: 0.3222\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3652 - val_loss: 0.3165\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3618 - val_loss: 0.3111\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3581 - val_loss: 0.3061\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3539 - val_loss: 0.3011\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3502 - val_loss: 0.2964\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3466 - val_loss: 0.2917\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3428 - val_loss: 0.2872\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3395 - val_loss: 0.2831\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3356 - val_loss: 0.2791\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3320 - val_loss: 0.2754\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3282 - val_loss: 0.2719\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3254 - val_loss: 0.2686\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3223 - val_loss: 0.2656\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3196 - val_loss: 0.2629\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3163 - val_loss: 0.2601\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3138 - val_loss: 0.2573\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3110 - val_loss: 0.2548\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3088 - val_loss: 0.2523\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.9117647058823529\n",
      "the testing accuracy for partial Neural Network is 0.9117647058823529\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9117647058823529\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.8823529411764706\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6074\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.9259\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6558 - val_loss: 0.6562\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6439 - val_loss: 0.6454\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6307 - val_loss: 0.6336\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6165 - val_loss: 0.6211\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6016 - val_loss: 0.6081\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5853 - val_loss: 0.5939\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5679 - val_loss: 0.5793\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5508 - val_loss: 0.5647\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5323 - val_loss: 0.5502\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5148 - val_loss: 0.5365\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4979 - val_loss: 0.5240\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4818 - val_loss: 0.5124\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4665 - val_loss: 0.5018\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4525 - val_loss: 0.4921\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4394 - val_loss: 0.4833\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4270 - val_loss: 0.4756\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.4158 - val_loss: 0.4684\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4052 - val_loss: 0.4618\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3952 - val_loss: 0.4559\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3862 - val_loss: 0.4505\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3783 - val_loss: 0.4455\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3699 - val_loss: 0.4409\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3626 - val_loss: 0.4368\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3556 - val_loss: 0.4331\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3491 - val_loss: 0.4299\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3431 - val_loss: 0.4262\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3374 - val_loss: 0.4232\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3316 - val_loss: 0.4205\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3266 - val_loss: 0.4179\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3220 - val_loss: 0.4155\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3174 - val_loss: 0.4132\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3135 - val_loss: 0.4116\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3094 - val_loss: 0.4099\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3057 - val_loss: 0.4083\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3027 - val_loss: 0.4068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2987 - val_loss: 0.4056\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2956 - val_loss: 0.4045\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2925 - val_loss: 0.4034\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2898 - val_loss: 0.4022\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2870 - val_loss: 0.4013\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2842 - val_loss: 0.4004\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2819 - val_loss: 0.3997\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2794 - val_loss: 0.3991\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2771 - val_loss: 0.3985\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2748 - val_loss: 0.3979\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2728 - val_loss: 0.3971\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2709 - val_loss: 0.3966\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2693 - val_loss: 0.3958\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2677 - val_loss: 0.3951\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2662 - val_loss: 0.3948\n",
      "the testing accuracy for partial Logistic Regression is 0.9117647058823529\n",
      "the testing accuracy for partial Support Vector Machine is 0.8529411764705882\n",
      "the testing accuracy for partial Neural Network is 0.9117647058823529\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9117647058823529\n",
      "the testing accuracy for partial Random Forest is 0.8529411764705882\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6296\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9852\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9852\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9852\n",
      "the testing accuracy for Logistic Regression is 0.9705882352941176\n",
      "the testing accuracy for Support Vector Machine is 0.9705882352941176\n",
      "the testing accuracy for Neural Network is 0.9705882352941176\n",
      "the testing accuracy for K-Nearest Neighbors is 0.9705882352941176\n",
      "the testing accuracy for Gaussian Discriminant Analysis is 0.9705882352941176\n",
      "the testing accuracy for Random Forest is 0.9705882352941176\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6863 - val_loss: 0.6788\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6837 - val_loss: 0.6759\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6807 - val_loss: 0.6726\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6776 - val_loss: 0.6686\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6737 - val_loss: 0.6636\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6695 - val_loss: 0.6577\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6647 - val_loss: 0.6510\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6592 - val_loss: 0.6426\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6522 - val_loss: 0.6328\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6442 - val_loss: 0.6213\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6359 - val_loss: 0.6094\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6259 - val_loss: 0.5958\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6150 - val_loss: 0.5802\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6027 - val_loss: 0.5638\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5901 - val_loss: 0.5460\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5764 - val_loss: 0.5281\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5630 - val_loss: 0.5103\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5490 - val_loss: 0.4924\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5352 - val_loss: 0.4748\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5225 - val_loss: 0.4581\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5099 - val_loss: 0.4417\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4981 - val_loss: 0.4266\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4871 - val_loss: 0.4127\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4766 - val_loss: 0.3987\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4669 - val_loss: 0.3857\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4581 - val_loss: 0.3735\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4486 - val_loss: 0.3627\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4410 - val_loss: 0.3524\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4333 - val_loss: 0.3437\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4270 - val_loss: 0.3351\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4197 - val_loss: 0.3267\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4140 - val_loss: 0.3187\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4078 - val_loss: 0.3119\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4027 - val_loss: 0.3055\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3970 - val_loss: 0.2996\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3931 - val_loss: 0.2942\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3876 - val_loss: 0.2888\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3834 - val_loss: 0.2834\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3795 - val_loss: 0.2785\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3753 - val_loss: 0.2735\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3714 - val_loss: 0.2691\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3676 - val_loss: 0.2652\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3641 - val_loss: 0.2612\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3612 - val_loss: 0.2577\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3582 - val_loss: 0.2546\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3555 - val_loss: 0.2531\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3527 - val_loss: 0.2502\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3498 - val_loss: 0.2482\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3473 - val_loss: 0.2450\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3449 - val_loss: 0.2425\n",
      "the testing accuracy for partial Logistic Regression is 0.9411764705882353\n",
      "the testing accuracy for partial Support Vector Machine is 0.9411764705882353\n",
      "the testing accuracy for partial Neural Network is 0.9411764705882353\n",
      "the testing accuracy for partial K-Nearest Neighbors is 0.9411764705882353\n",
      "the testing accuracy for partial Gaussian Discriminant Analysis is 0.9411764705882353\n",
      "the testing accuracy for partial Random Forest is 0.9705882352941176\n",
      "Full Feature Set:\n",
      "\n",
      "Logistic Regression:\n",
      "\n",
      "average: 0.98\n",
      "standard deviation: 0.02\n",
      "\n",
      "\n",
      "SVM:\n",
      "\n",
      "average: 0.98\n",
      "standard deviation: 0.02\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "average: 0.98\n",
      "standard deviation: 0.02\n",
      "\n",
      "\n",
      "GDA:\n",
      "\n",
      "average: 0.98\n",
      "standard deviation: 0.02\n",
      "\n",
      "\n",
      "KNN:\n",
      "\n",
      "average: 0.98\n",
      "standard deviation: 0.02\n",
      "\n",
      "\n",
      "Neural Network:\n",
      "\n",
      "average: 0.98\n",
      "standard deviation: 0.02\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Partial Feature Set:\n",
      "\n",
      "Logistic Regression:\n",
      "\n",
      "average: 0.91\n",
      "standard deviation: 0.05\n",
      "\n",
      "\n",
      "SVM:\n",
      "\n",
      "average: 0.9\n",
      "standard deviation: 0.05\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "average: 0.88\n",
      "standard deviation: 0.11\n",
      "\n",
      "\n",
      "GDA:\n",
      "\n",
      "average: 0.91\n",
      "standard deviation: 0.05\n",
      "\n",
      "\n",
      "KNN:\n",
      "\n",
      "average: 0.91\n",
      "standard deviation: 0.05\n",
      "\n",
      "\n",
      "Neural Network:\n",
      "\n",
      "average: 0.91\n",
      "standard deviation: 0.05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Option1_data.csv\")\n",
    "X=data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "X_partial = data.iloc[:,:2]\n",
    "\n",
    "# runModels(X,y)\n",
    "# runModels(X_partial,y,partial=True)\n",
    "names=[\"Logistic Regression\",\"SVM\",\"Random Forest\", \"GDA\", \"KNN\", \"Neural Network\"]\n",
    "lists=[[],[],[],[],[],[]]\n",
    "lists_partial=[[],[],[],[],[],[]]\n",
    "for i in range(25):\n",
    "\tlists=runModels(X,y,lists)\n",
    "\tlists_partial=runModels(X_partial,y,lists_partial,partial=True)\n",
    "\n",
    "print(\"Full Feature Set:\\n\")\n",
    "for i in range(len(lists)):\n",
    "\tprint(names[i]+\":\\n\")\n",
    "\tavg = round(np.mean(lists[i]),2)\n",
    "\tstd = round(np.std(lists[i],ddof=1),2)\n",
    "\tprint(\"average: \"+str(avg))\n",
    "\tprint(\"standard deviation: \"+str(std)+\"\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\\nPartial Feature Set:\\n\")\n",
    "for i in range(len(lists_partial)):\n",
    "\tprint(names[i]+\":\\n\")\n",
    "\tavg = round(np.mean(lists_partial[i]),2)\n",
    "\tstd = round(np.std(lists_partial[i],ddof=1),2)\n",
    "\tprint(\"average: \"+str(avg))\n",
    "\tprint(\"standard deviation: \"+str(std)+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
